{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QWhuV0zN6jII",
        "outputId": "92158b69-5d3f-4559-e450-8b9f62dd49a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QWhuV0zN6jII",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pickle5"
      ],
      "metadata": {
        "id": "Rl_Rp7JA7ZSA",
        "outputId": "440cc2e5-924f-4ff7-c9b7-a3ccca5a6f7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Rl_Rp7JA7ZSA",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20 kB 20.8 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 30 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 51 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 61 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 71 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 81 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 92 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 102 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 112 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 122 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 133 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 143 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 153 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 163 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 174 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 184 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 194 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 204 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 215 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 225 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 235 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 245 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 8.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle5 as pickle"
      ],
      "metadata": {
        "id": "N8ayuz1v6qNz"
      },
      "id": "N8ayuz1v6qNz",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "challenging-intent",
      "metadata": {
        "id": "challenging-intent"
      },
      "outputs": [],
      "source": [
        "data_dir = 'drive/MyDrive/stat940/dc2'\n",
        "\n",
        "with open(f\"{data_dir}/train.pickle\", \"rb\") as f:\n",
        "    train_dict = pickle.load(f)\n",
        "\n",
        "with open(f\"{data_dir}/test.pickle\", \"rb\") as f:  \n",
        "    test_dict = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install folium==0.2.1\n",
        "!pip install tensorboardX\n",
        "!pip install transformers==2.3.0"
      ],
      "metadata": {
        "id": "h6khCoe1JcBl",
        "outputId": "221127f9-3dbd-433c-cd6e-b62ea2ff7850",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "h6khCoe1JcBl",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting folium==0.2.1\n",
            "  Downloading folium-0.2.1.tar.gz (69 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 20 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 40 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 51 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 61 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 69 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from folium==0.2.1) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->folium==0.2.1) (2.0.1)\n",
            "Building wheels for collected packages: folium\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folium: filename=folium-0.2.1-py3-none-any.whl size=79808 sha256=5ff7dfc87422bad8fccd227e6bb83239611e1bfc3d3d8d7eb6bf519c920221f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/f0/3a/3f79a6914ff5affaf50cabad60c9f4d565283283c97f0bdccf\n",
            "Successfully built folium\n",
            "Installing collected packages: folium\n",
            "  Attempting uninstall: folium\n",
            "    Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "Successfully installed folium-0.2.1\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.5)\n",
            "Requirement already satisfied: transformers==2.3.0 in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (4.63.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (0.1.96)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (1.21.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (1.21.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (0.0.47)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.12 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (1.24.12)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.12->boto3->transformers==2.3.0) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.12->boto3->transformers==2.3.0) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.12->boto3->transformers==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n",
        "# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\" Finetuning the library models for sequence classification on GLUE (Bert, XLM, XLNet, RoBERTa).\"\"\"\n",
        "\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import argparse\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import csv\n",
        "import codecs\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset, Dataset)\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tensorboardX import SummaryWriter\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import (WEIGHTS_NAME, BertConfig,\n",
        "                    BertForSequenceClassification, BertTokenizer)\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from transformers import glue_compute_metrics as compute_metrics\n",
        "from transformers import glue_output_modes as output_modes\n",
        "from transformers import glue_processors as processors\n",
        "from transformers import glue_convert_examples_to_features as convert_examples_to_features\n",
        "from transformers import DataProcessor, InputExample, InputFeatures\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "nLSsdm4pJQ23"
      },
      "id": "nLSsdm4pJQ23",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ALL_MODELS = sum((tuple(\n",
        "#    conf.pretrained_config_archive_map.keys()) for conf in (\n",
        "#        BertConfig)), ())\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    'bert': (BertConfig, BertForSequenceClassification, BertTokenizer)\n",
        "}\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "class MyTestDataset(Dataset):\n",
        "    \"\"\"Dataset during test time\"\"\"\n",
        "\n",
        "    def __init__(self, tensor_data, sents):\n",
        "        assert len(tensor_data) == len(sents)\n",
        "        self.tensor_data = tensor_data\n",
        "        self.rows = sents\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.tensor_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.tensor_data[idx], self.rows[idx])\n",
        "    \n",
        "def evaluate_test(args, model, tokenizer, prefix=\"\"):\n",
        "    \n",
        "    if args.local_rank not in [-1, 0] and not evaluate:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
        "\n",
        "    processor = PairProcessor()\n",
        "    output_mode = \"classification\"\n",
        "    \n",
        "    cached_features_file = os.path.join(args.data_dir, 'cached_{}_{}_{}_{}'.format(\n",
        "        'test',\n",
        "        'bert',\n",
        "        str(args.max_seq_length),\n",
        "        'pair_order'))\n",
        "    \n",
        "    if os.path.exists(cached_features_file):\n",
        "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "        features = torch.load(cached_features_file)\n",
        "        lines = torch.load(cached_features_file + '_lines')\n",
        "    else:\n",
        "        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n",
        "        label_list = processor.get_labels()\n",
        "\n",
        "        examples, lines = processor.get_test_examples(args.data_dir)\n",
        "        features = convert_examples_to_features(\n",
        "            examples,\n",
        "            tokenizer,\n",
        "            label_list=label_list,\n",
        "            max_length=args.max_seq_length,\n",
        "            output_mode=output_mode,\n",
        "            pad_on_left=False,                 # pad on the left for xlnet\n",
        "            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
        "            pad_token_segment_id=0,\n",
        "        )\n",
        "        if args.local_rank in [-1, 0]:\n",
        "            logger.info(\n",
        "                \"Saving features into cached file %s\", \n",
        "                cached_features_file)\n",
        "            torch.save(features, cached_features_file)\n",
        "            torch.save(lines, cached_features_file + '_lines')\n",
        "        \n",
        "    if args.local_rank == 0 and not evaluate:\n",
        "        torch.distributed.barrier() \n",
        "\n",
        "    # Convert to Tensors and build dataset\n",
        "    all_input_ids = torch.tensor(\n",
        "        [f.input_ids for f in features], dtype=torch.long)\n",
        "    all_attention_mask = torch.tensor(\n",
        "        [f.attention_mask for f in features], dtype=torch.long)\n",
        "    all_token_type_ids = torch.tensor(\n",
        "        [f.token_type_ids for f in features], dtype=torch.long)\n",
        "    all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n",
        "\n",
        "    dataset = TensorDataset(\n",
        "        all_input_ids, \n",
        "        all_attention_mask, \n",
        "        all_token_type_ids, \n",
        "        all_labels\n",
        "        )\n",
        "\n",
        "    \n",
        "    eval_outputs_dirs = (args.output_dir,)\n",
        "    file_h = codecs.open(args.data_dir + \"test_results.tsv\", \"w\", \"utf-8\")\n",
        "    outF = csv.writer(file_h, delimiter='\\t')\n",
        "\n",
        "    results = {}\n",
        "    for eval_output_dir in eval_outputs_dirs:\n",
        "        eval_dataset = MyTestDataset(dataset, lines)\n",
        "        \n",
        "        if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
        "            os.makedirs(eval_output_dir)\n",
        "\n",
        "        args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
        "        eval_sampler = SequentialSampler(eval_dataset)\n",
        "        \n",
        "        eval_dataloader = DataLoader(\n",
        "            eval_dataset, \n",
        "            sampler=eval_sampler, \n",
        "            batch_size=args.eval_batch_size\n",
        "            )\n",
        "\n",
        "        # Eval!\n",
        "        logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "        logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "        logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "        eval_loss = 0.0\n",
        "        nb_eval_steps = 0\n",
        "        preds = None\n",
        "        out_label_ids = None\n",
        "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "            model.eval()\n",
        "            row = batch[1]\n",
        "            rows = {\n",
        "                'guid': row[0],\n",
        "                'text_a': row[1],\n",
        "                'text_b': row[2],\n",
        "                'labels': row[3],\n",
        "                'pos_a': row[4],\n",
        "                'pos_b':row[5]\n",
        "            }\n",
        "            del row\n",
        "            batch = tuple(t.to(args.device) for t in batch[0])\n",
        "\n",
        "            with torch.no_grad():\n",
        "                inputs = {\n",
        "                        'input_ids':      batch[0],\n",
        "                        'attention_mask': batch[1],\n",
        "                        'token_type_ids': batch[2],\n",
        "                        'labels':         batch[3]}\n",
        "\n",
        "                outputs = model(**inputs)\n",
        "                tmp_eval_loss, logits = outputs[:2]\n",
        "                eval_loss += tmp_eval_loss.mean().item()\n",
        "            nb_eval_steps += 1\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            tmp_pred = np.argmax(logits, axis=1)\n",
        "            for widx in range(logits.shape[0]):\n",
        "                outF.writerow([rows['guid'][widx], rows['text_a'][widx], \\\n",
        "                rows['text_b'][widx], rows['labels'][widx], \\\n",
        "                rows['pos_a'][widx], rows['pos_b'][widx], \\\n",
        "                logits[widx][0], logits[widx][1], tmp_pred[widx]])\n",
        "            if preds is None:\n",
        "                preds = logits\n",
        "                out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
        "            else:\n",
        "                preds = np.append(preds, logits, axis=0)\n",
        "                out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "        eval_loss = eval_loss / nb_eval_steps\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "\n",
        "        result = compute_metrics(\"mnli\", preds, out_label_ids)\n",
        "        results.update(result)\n",
        "\n",
        "        file_h.close()\n",
        "        output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n",
        "        with open(output_eval_file, \"w\") as writer:\n",
        "            logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "            for key in sorted(result.keys()):\n",
        "                logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "\n",
        "    return results\n",
        "\n",
        "def evaluate(args, model, tokenizer, prefix=\"\"):\n",
        "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "    \n",
        "    eval_outputs_dirs = (args.output_dir,)\n",
        "\n",
        "    results = {}\n",
        "    for eval_output_dir in eval_outputs_dirs:\n",
        "        eval_dataset = load_and_cache_examples(args, tokenizer, evaluate=True)\n",
        "\n",
        "        if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
        "            os.makedirs(eval_output_dir)\n",
        "\n",
        "        args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
        "        # Note that DistributedSampler samples randomly\n",
        "        eval_sampler = SequentialSampler(eval_dataset) if args.local_rank == -1 else DistributedSampler(eval_dataset)\n",
        "        eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
        "\n",
        "        # Eval!\n",
        "        logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "        logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "        logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "        eval_loss = 0.0\n",
        "        nb_eval_steps = 0\n",
        "        preds = None\n",
        "        out_label_ids = None\n",
        "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "            model.eval()\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                inputs = {'input_ids':      batch[0],\n",
        "                          'attention_mask': batch[1],\n",
        "                          'token_type_ids': batch[2],\n",
        "                          'labels':         batch[3]\n",
        "                        }\n",
        "                outputs = model(**inputs)\n",
        "                tmp_eval_loss, logits = outputs[:2]\n",
        "\n",
        "                eval_loss += tmp_eval_loss.mean().item()\n",
        "            nb_eval_steps += 1\n",
        "            if preds is None:\n",
        "                preds = logits.detach().cpu().numpy()\n",
        "                out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
        "            else:\n",
        "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "                out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "        eval_loss = eval_loss / nb_eval_steps\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "\n",
        "        result = compute_metrics(\"mnli\", preds, out_label_ids)\n",
        "        results.update(result)\n",
        "\n",
        "        output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n",
        "        with open(output_eval_file, \"w\") as writer:\n",
        "            logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "            for key in sorted(result.keys()):\n",
        "                logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def load_and_cache_examples(args, tokenizer, evaluate=False):\n",
        "    if args.local_rank not in [-1, 0] and not evaluate:\n",
        "        torch.distributed.barrier()  \n",
        "\n",
        "    processor = PairProcessor()\n",
        "    output_mode = 'classification'\n",
        "    \n",
        "    cached_features_file = os.path.join(\n",
        "        args.data_dir, 'cached_{}_{}_{}_{}'.format(\n",
        "        'dev' if evaluate else 'train',\n",
        "        'bert',\n",
        "        str(args.max_seq_length),\n",
        "        'pair_order'))\n",
        "\n",
        "    if os.path.exists(cached_features_file):\n",
        "        logger.info(\n",
        "            \"Loading features from cached file %s\", cached_features_file)\n",
        "        features = torch.load(cached_features_file)\n",
        "    else:\n",
        "        logger.info(\n",
        "            \"Creating features from dataset file at %s\", args.data_dir)\n",
        "        label_list = processor.get_labels()\n",
        "        examples = processor.get_dev_examples(args.data_dir) if evaluate else processor.get_train_examples(args.data_dir)\n",
        "        features = convert_examples_to_features(examples,\n",
        "                                    tokenizer,\n",
        "                                    label_list=label_list,\n",
        "                                    max_length=args.max_seq_length,\n",
        "                                    output_mode=output_mode,\n",
        "                                    pad_on_left=False,                 # pad on the left for xlnet\n",
        "                                    pad_token=tokenizer.convert_tokens_to_ids(\n",
        "                                        [tokenizer.pad_token])[0],\n",
        "                                    pad_token_segment_id=0,\n",
        "                                    )\n",
        "        if args.local_rank in [-1, 0]:\n",
        "            logger.info(\n",
        "                \"Saving features into cached file %s\", cached_features_file)\n",
        "            torch.save(features, cached_features_file)\n",
        "        \n",
        "    if args.local_rank == 0 and not evaluate:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
        "\n",
        "    # Convert to Tensors and build dataset\n",
        "    all_input_ids = torch.tensor(\n",
        "        [f.input_ids for f in features], dtype=torch.long)\n",
        "    all_attention_mask = torch.tensor(\n",
        "        [f.attention_mask for f in features], dtype=torch.long)\n",
        "    all_token_type_ids = torch.tensor(\n",
        "        [f.token_type_ids for f in features], dtype=torch.long)\n",
        "\n",
        "    all_labels = torch.tensor(\n",
        "        [f.label for f in features], dtype=torch.long)\n",
        "\n",
        "    dataset = TensorDataset(\n",
        "        all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
        "    return dataset\n",
        "\n",
        "class PairProcessor(DataProcessor):\n",
        "    \"\"\"Pair Processor for the pair ordering task.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
        "    \n",
        "    def get_test_examples(self, data_dir):\n",
        "        return self._create_test_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
        "    \n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return [\"0\", \"1\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (_, line) in enumerate(lines):\n",
        "            guid = \"%s-%s\" % (set_type, line[0])\n",
        "            try:\n",
        "                text_a = line[1].lower()\n",
        "                text_b = line[2].lower()\n",
        "                label = line[3]\n",
        "            except IndexError:\n",
        "                print('cannot read the line: ' + line)\n",
        "                continue\n",
        "            examples.append(InputExample(\n",
        "                                        guid=guid, \n",
        "                                        text_a=text_a, \n",
        "                                        text_b=text_b, \n",
        "                                        label=label\n",
        "                                    ))\n",
        "        return examples\n",
        "    \n",
        "    def _create_test_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples, rows = [], []\n",
        "        for (_, line) in enumerate(lines):\n",
        "            guid = \"%s-%s\" % (set_type, line[0])\n",
        "            try:\n",
        "                text_a = line[1].lower()\n",
        "                text_b = line[2].lower()\n",
        "                label = line[3]\n",
        "            except IndexError:\n",
        "                print('cannot read the line: ' + line)\n",
        "                continue\n",
        "            examples.append(InputExample(\n",
        "                                    guid=guid, \n",
        "                                    text_a=text_a, \n",
        "                                    text_b=text_b, \n",
        "                                    label=label\n",
        "                            ))\n",
        "            rows.append(line)\n",
        "        return examples, rows"
      ],
      "metadata": {
        "id": "Q4g4g-aj7d4_"
      },
      "id": "Q4g4g-aj7d4_",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8vkRlDd0KgnH"
      },
      "id": "8vkRlDd0KgnH",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "                    level = logging.INFO)\n",
        "\n",
        "# Set seed\n",
        "set_seed(42)\n",
        "\n",
        "_, model_class, tokenizer_class = (BertConfig, BertForSequenceClassification, BertTokenizer)\n",
        "\n",
        "tokenizer = tokenizer_class.from_pretrained('bert-base-uncased')\n",
        "model = model_class.from_pretrained('bert-base-uncased')\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "rUy8KAlbMfYY",
        "outputId": "5e3ac479-0188-4e63-e965-30a66c56d1a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rUy8KAlbMfYY",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03/04/2022 19:23:24 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "03/04/2022 19:23:25 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "03/04/2022 19:23:25 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "03/04/2022 19:23:25 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "03/04/2022 19:23:29 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "03/04/2022 19:23:29 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "topological-sort.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}